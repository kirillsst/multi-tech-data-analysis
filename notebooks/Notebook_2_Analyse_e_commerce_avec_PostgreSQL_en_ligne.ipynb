{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I43NxonzOSDg"
      },
      "source": [
        "# Notebook 2 - SQL avec vraies bases de donn√©es\n",
        "## Analyse e-commerce avec PostgreSQL en ligne\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JItQV6o4Ojrm"
      },
      "source": [
        "\n",
        "### üéØ Objectifs p√©dagogiques\n",
        "- Connecter Python √† une vraie base de donn√©es PostgreSQL\n",
        "- √âcrire des requ√™tes SQL complexes sur des donn√©es r√©elles\n",
        "- Impl√©menter des analyses RFM avec SQL\n",
        "- Int√©grer SQL et pandas pour des analyses avanc√©es\n",
        "- G√©rer les connexions et la s√©curit√©\n",
        "\n",
        "### üõçÔ∏è Contexte du projet\n",
        "Vous analysez les donn√©es d'un vrai dataset e-commerce (Brazilian E-Commerce Public Dataset) h√©berg√© sur une base PostgreSQL.\n",
        "\n",
        "Objectif : cr√©er une segmentation client√®le pour optimiser les campagnes marketing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K79TBMVvOuoj"
      },
      "source": [
        "## Partie 1 : Connexion √† la base de donn√©es r√©elle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq7n18iwPBPe"
      },
      "source": [
        "### üîß Installation et configuration\n",
        "\n",
        "\n",
        "# Installation des d√©pendances\n",
        "\n",
        "\n",
        "```\n",
        "pip install psycopg2-binary sqlalchemy pandas python-dotenv\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "_NuY2FHuOhu3"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine, text\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEbORVz5PXMa"
      },
      "source": [
        "### üåê Base de donn√©es PostgreSQL gratuite (ElephantSQL)\n",
        "\n",
        "**Option 1 : ElephantSQL (20MB gratuit)**\n",
        "1. Cr√©ez un compte sur [elephantsql.com](https://www.elephantsql.com/)\n",
        "2. Cr√©ez une instance \"Tiny Turtle\" (gratuite)\n",
        "3. R√©cup√©rez vos credentials\n",
        "\n",
        "**Option 2 : Supabase (500MB gratuit)**\n",
        "1. Cr√©ez un compte sur [supabase.com](https://supabase.com/)\n",
        "2. Cr√©ez un nouveau projet\n",
        "3. R√©cup√©rez l'URL de connexion PostgreSQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ytLvCF3fQxRJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection successful!\n",
            "Current Time: ('PostgreSQL 17.4 on aarch64-unknown-linux-gnu, compiled by gcc (GCC) 13.2.0, 64-bit',)\n",
            "Connection closed.\n"
          ]
        }
      ],
      "source": [
        "# Configuration de connexion (√† adapter selon votre provider)\n",
        "load_dotenv()\n",
        "\n",
        "# Fetch variables\n",
        "USER = os.getenv(\"USER\")\n",
        "PASSWORD = os.getenv(\"PASSWORD\")\n",
        "HOST = os.getenv(\"HOST\")\n",
        "PORT = os.getenv(\"PORT\")\n",
        "DBNAME = os.getenv(\"DBNAME\")\n",
        "\n",
        "DATABASE_CONFIG = {\n",
        "    'host': HOST,  # Ou votre host Supabase\n",
        "    'database': DBNAME,\n",
        "    'user': DBNAME,\n",
        "    'password': PASSWORD,\n",
        "    'port': PORT\n",
        "}\n",
        "    \n",
        "# Cr√©ation de l'engine SQLAlchemy\n",
        "engine = create_engine(\n",
        "    f\"postgresql://{USER}:{PASSWORD}@\"\n",
        "    f\"{HOST}:{PORT}/{DBNAME}\"\n",
        ")\n",
        "\n",
        "# Test de connexion\n",
        "def test_connection():\n",
        "    \"\"\"\n",
        "    Testez votre connexion √† la base\n",
        "\n",
        "    √âtapes :\n",
        "    1. Utilisez pd.read_sql() pour ex√©cuter \"SELECT version()\"\n",
        "    2. Affichez la version PostgreSQL\n",
        "    3. G√©rez les erreurs de connexion\n",
        "    \"\"\"\n",
        "    # Connect to the database\n",
        "    try:\n",
        "        connection = psycopg2.connect(\n",
        "            user=USER,\n",
        "            password=PASSWORD,\n",
        "            host=HOST,\n",
        "            port=PORT,\n",
        "            dbname=DBNAME\n",
        "        )\n",
        "        print(\"Connection successful!\")\n",
        "        \n",
        "        # Create a cursor to execute SQL queries\n",
        "        cursor = connection.cursor()\n",
        "        \n",
        "        # Example query\n",
        "        cursor.execute(\"SELECT version();\")\n",
        "        result = cursor.fetchone()\n",
        "        print(\"Current Time:\", result)\n",
        "\n",
        "        # Close the cursor and connection\n",
        "        cursor.close()\n",
        "        connection.close()\n",
        "        print(\"Connection closed.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to connect: {e}\")\n",
        "test_connection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXfOgAxGQ3b5"
      },
      "source": [
        "\n",
        "## Partie 2 : Import du dataset e-commerce\n",
        "\n",
        "### üìä Dataset Brazilian E-Commerce\n",
        "Nous utilisons le c√©l√®bre dataset Olist (100k commandes r√©elles).\n",
        "\n",
        "**Tables √† cr√©er :**\n",
        "1. **customers** : customer_id, customer_city, customer_state\n",
        "2. **orders** : order_id, customer_id, order_status, order_date, order_delivered_date\n",
        "3. **order_items** : order_id, product_id, seller_id, price, freight_value\n",
        "4. **products** : product_id, product_category, product_weight_g\n",
        "5. **sellers** : seller_id, seller_city, seller_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "2_uVipWkQ_W8"
      },
      "outputs": [],
      "source": [
        "### üì• Import des donn√©es via API\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "def download_olist_dataset():\n",
        "    \"\"\"\n",
        "    T√©l√©charge le dataset Olist depuis Kaggle API\n",
        "\n",
        "    Alternative : Utilisez l'API publique de l'IBGE (Institut br√©silien)\n",
        "    pour des donn√©es e-commerce synth√©tiques mais r√©alistes\n",
        "    \"\"\"\n",
        "\n",
        "    # URL des donn√©es publiques br√©siliennes\n",
        "    IBGE_API = \"https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\"\n",
        "\n",
        "    # R√©cup√©ration des donn√©es de villes (pour la g√©olocalisation)\n",
        "    cities_url = f\"{IBGE_API}localidades/municipios\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(cities_url)\n",
        "        cities_data = response.json()\n",
        "\n",
        "        # Convertir en DataFrame\n",
        "        cities_df = pd.DataFrame(cities_data)\n",
        "\n",
        "        # Votre code pour nettoyer et structurer\n",
        "        # Cr√©ez des donn√©es e-commerce r√©alistes bas√©es sur ces villes\n",
        "        return cities_df\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur API IBGE : {e}\")\n",
        "        return None\n",
        "# G√©n√©ration de donn√©es e-commerce r√©alistes\n",
        "def generate_ecommerce_data(cities_df, n_customers=10000):\n",
        "    \"\"\"\n",
        "    G√©n√®re des donn√©es e-commerce r√©alistes\n",
        "\n",
        "    √âtapes guid√©es :\n",
        "    1. S√©lectionnez 50 villes br√©siliennes al√©atoirement\n",
        "    2. Cr√©ez des clients avec distribution r√©aliste\n",
        "    3. G√©n√©rez des commandes avec saisonnalit√©\n",
        "    4. Ajoutez des produits avec cat√©gories coh√©rentes\n",
        "    5. Calculez des prix et frais de port bas√©s sur la distance\n",
        "    \"\"\"\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "GqGIXooNSTjp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           order_id  order_item_id  \\\n",
            "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
            "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
            "2  000229ec398224ef6ca0657da4fc703e              1   \n",
            "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
            "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
            "5  00048cc3ae777c65dbb7d2a0634bc1ea              1   \n",
            "6  00054e8431b9d7675808bcb819fb4a32              1   \n",
            "7  000576fe39319847cbb9d288c5617fa6              1   \n",
            "8  0005a1a1728c9d785b8e2b08b904576c              1   \n",
            "9  0005f50442cb953dcd1d21e1fb923495              1   \n",
            "\n",
            "                         product_id                         seller_id  \\\n",
            "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
            "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
            "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
            "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
            "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
            "5  ef92defde845ab8450f9d70c526ef70f  6426d21aca402a131fc0a5d0960a3c90   \n",
            "6  8d4f2bb7e93e6710a28f34fa83ee7d28  7040e82f899a04d1b434b795a43b4617   \n",
            "7  557d850972a7d6f792fd18ae1400d9b6  5996cddab893a4652a15592fb58ab8db   \n",
            "8  310ae3c140ff94b03219ad0adc3c778f  a416b6a846a11724393025641d4edd5e   \n",
            "9  4535b0e1091c278dfd193e5a1d63b39f  ba143b05f0110f0dc71ad71b4466ce92   \n",
            "\n",
            "   shipping_limit_date   price  freight_value  \n",
            "0  2017-09-19 09:45:35   58.90          13.29  \n",
            "1  2017-05-03 11:05:13  239.90          19.93  \n",
            "2  2018-01-18 14:48:30  199.00          17.87  \n",
            "3  2018-08-15 10:10:18   12.99          12.79  \n",
            "4  2017-02-13 13:57:51  199.90          18.14  \n",
            "5  2017-05-23 03:55:27   21.90          12.69  \n",
            "6  2017-12-14 12:10:31   19.90          11.85  \n",
            "7  2018-07-10 12:30:45  810.00          70.75  \n",
            "8  2018-03-26 18:31:29  145.95          11.65  \n",
            "9  2018-07-06 14:10:56   53.99          11.40  \n"
          ]
        }
      ],
      "source": [
        "### üóÉÔ∏è Cr√©ation des tables SQL\n",
        "df_olist_customers = pd.read_csv(\"~/multi-tech-data-analysis/archive/olist_order_items_dataset.csv\")\n",
        "print(df_olist_customers.head(10))\n",
        "\n",
        "def create_tables():\n",
        "    \"\"\"\n",
        "    Cr√©ez les tables dans PostgreSQL\n",
        "\n",
        "    Tips :\n",
        "    - Utilisez des SERIAL pour les IDs auto-increment\n",
        "    - Ajoutez des index sur les cl√©s √©trang√®res\n",
        "    - Incluez des contraintes de validation\n",
        "    \"\"\"\n",
        "\n",
        "    create_customers = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS customers (\n",
        "        customer_id SERIAL PRIMARY KEY,\n",
        "        customer_unique_id VARCHAR(50) UNIQUE,\n",
        "        customer_city VARCHAR(100),\n",
        "        customer_state VARCHAR(2),\n",
        "        customer_zip_code VARCHAR(10),\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    );\n",
        "    \"\"\"\n",
        "    create_orders = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS customer_orders(\n",
        "        order_id SERIAL PRIMARY KEY,\n",
        "        customer_id INTEGER REFERENCES customers(customer_id),\n",
        "        order_status VARCHAR(50),\n",
        "        order_purchase_timestamp TIMESTAMP,\n",
        "        order_approved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "        order_delivered_carrier_date TIMESTAMP,\n",
        "        order_delivered_customer_date TIMESTAMP,\n",
        "        order_estimated_delivery_date TIMESTAMP\n",
        "    );\n",
        "    \"\"\"\n",
        "    create_products = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS products(\n",
        "        product_id SERIAL PRIMARY KEY,\n",
        "        product_category_name VARCHAR(50),\n",
        "        product_name_lenght FLOAT,\n",
        "        product_description_lenght FLOAT,\n",
        "        product_photos_qty FLOAT\n",
        "    )\n",
        "    \"\"\"\n",
        "    create_sellers = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS sellers(\n",
        "    seller_id SERIAL PRIMARY KEY,\n",
        "    seller_zip_code_prefix VARCHAR(10),\n",
        "    seller_city VARCHAR(50),\n",
        "    seller_state CHAR(2)\n",
        "    )\n",
        "    \"\"\"\n",
        "    create_order_items = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS order_items(\n",
        "        order_item_id SERIAL PRIMARY KEY,\n",
        "        order_id INTEGER REFERENCES customer_orders(order_id),\n",
        "        product_id INTEGER REFERENCES products(product_id),\n",
        "        seller_id INTEGER REFERENCES sellers(seller_id),\n",
        "        shipping_limit_date TIMESTAMP,\n",
        "        price NUMERIC(10, 2),\n",
        "        freight_value NUMERIC(10, 2)\n",
        "    );\n",
        "    \"\"\"\n",
        "    # Compl√©tez pour les autres tables\n",
        "    # N'oubliez pas les contraintes de cl√©s √©trang√®res !\n",
        "\n",
        "    with engine.connect() as conn:\n",
        "        conn.execute(text(create_order_items))\n",
        "        # Ex√©cutez les autres CREATE TABLE\n",
        "        conn.commit()\n",
        "create_tables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBQ_BY-QT4dO"
      },
      "source": [
        "## Partie 3 : Requ√™tes SQL avanc√©es\n",
        "\n",
        "\n",
        "### üîç Analyses SQL √† impl√©menter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdl5RNOBUAV2"
      },
      "source": [
        "#### 1. Analyse RFM (R√©cence, Fr√©quence, Montant)\n",
        "```sql\n",
        "-- Votre d√©fi : Calculer les m√©triques RFM pour chaque client\n",
        "WITH customer_metrics AS (\n",
        "    SELECT\n",
        "        c.customer_id,\n",
        "        c.customer_state,\n",
        "        -- R√©cence : jours depuis dernier achat\n",
        "        -- Fr√©quence : nombre de commandes\n",
        "        -- Montant : total d√©pens√©\n",
        "        \n",
        "        -- Compl√©tez cette requ√™te CTE\n",
        "        \n",
        "    FROM customers c\n",
        "    JOIN orders o ON c.customer_id = o.customer_id\n",
        "    JOIN order_items oi ON o.order_id = oi.order_id\n",
        "    WHERE o.order_status = 'delivered'\n",
        "    GROUP BY c.customer_id, c.customer_state\n",
        ")\n",
        "\n",
        "-- Cr√©ez les segments RFM (Champions, Loyaux, √Ä risque, etc.)\n",
        "SELECT\n",
        "    customer_id,\n",
        "    customer_state,\n",
        "    recency_score,\n",
        "    frequency_score,\n",
        "    monetary_score,\n",
        "    CASE\n",
        "        WHEN recency_score >= 4 AND frequency_score >= 4 THEN 'Champions'\n",
        "        WHEN recency_score >= 3 AND frequency_score >= 3 THEN 'Loyal Customers'\n",
        "        -- Ajoutez les autres segments\n",
        "        ELSE 'Others'\n",
        "    END as customer_segment\n",
        "FROM customer_metrics;\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "TWF9rpZSUMp5"
      },
      "outputs": [],
      "source": [
        "#### 2. Analyse g√©ographique des ventes\n",
        "\n",
        "def geographic_sales_analysis():\n",
        "    \"\"\"\n",
        "    Analysez les performances par √©tat/r√©gion\n",
        "\n",
        "    Requ√™tes √† √©crire :\n",
        "    1. Top 10 des √©tats par CA\n",
        "    2. Croissance MoM par r√©gion\n",
        "    3. Taux de conversion par ville\n",
        "    4. Distance moyenne vendeur-acheteur\n",
        "    \"\"\"\n",
        "\n",
        "    query_top_states = \"\"\"\n",
        "    -- Votre requ√™te SQL ici\n",
        "    -- Utilisez des JOINs et GROUP BY\n",
        "    -- Calculez le CA, nombre de commandes, panier moyen\n",
        "    \"\"\"\n",
        "\n",
        "    return pd.read_sql(query_top_states, engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OE-UHLKY8-K"
      },
      "source": [
        "#### 3. Analyse temporelle et saisonnalit√©\n",
        "```sql\n",
        "-- D√©tectez les patterns saisonniers\n",
        "SELECT\n",
        "    EXTRACT(YEAR FROM order_date) as year,\n",
        "    EXTRACT(MONTH FROM order_date) as month,\n",
        "    EXTRACT(DOW FROM order_date) as day_of_week,\n",
        "    COUNT(*) as order_count,\n",
        "    SUM(price + freight_value) as total_revenue,\n",
        "    AVG(price + freight_value) as avg_order_value\n",
        "FROM orders o\n",
        "JOIN order_items oi ON o.order_id = oi.order_id\n",
        "WHERE order_status = 'delivered'\n",
        "GROUP BY ROLLUP(\n",
        "    EXTRACT(YEAR FROM order_date),\n",
        "    EXTRACT(MONTH FROM order_date),\n",
        "    EXTRACT(DOW FROM order_date)\n",
        ")\n",
        "ORDER BY year, month, day_of_week;\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq43e3mfZC8d"
      },
      "source": [
        "## Partie 4 : Analyse pr√©dictive avec SQL\n",
        "\n",
        "### üîÆ Mod√®les simples en SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "bY5mfxFoaL2K"
      },
      "outputs": [],
      "source": [
        "#### 1. Pr√©diction de churn\n",
        "\n",
        "def churn_prediction_sql():\n",
        "    \"\"\"\n",
        "    Identifiez les clients √† risque de churn\n",
        "\n",
        "    Indicateurs :\n",
        "    - Pas d'achat depuis X jours\n",
        "    - Baisse de fr√©quence d'achat\n",
        "    - Diminution du panier moyen\n",
        "    - Changement de comportement g√©ographique\n",
        "    \"\"\"\n",
        "\n",
        "    churn_query = \"\"\"\n",
        "    WITH customer_activity AS (\n",
        "        -- Calculez les m√©triques d'activit√© r√©cente\n",
        "        -- Comparez avec l'historique du client\n",
        "        -- Scorez le risque de churn\n",
        "    )\n",
        "\n",
        "    SELECT\n",
        "        customer_id,\n",
        "        days_since_last_order,\n",
        "        order_frequency_trend,\n",
        "        monetary_trend,\n",
        "        churn_risk_score,\n",
        "        CASE\n",
        "            WHEN churn_risk_score > 0.7 THEN 'High Risk'\n",
        "            WHEN churn_risk_score > 0.4 THEN 'Medium Risk'\n",
        "            ELSE 'Low Risk'\n",
        "        END as churn_segment\n",
        "    FROM customer_activity;\n",
        "    \"\"\"\n",
        "\n",
        "    return pd.read_sql(churn_query, engine)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB2D1PDraVu4"
      },
      "source": [
        "#### 2. Recommandations produits\n",
        "```sql\n",
        "-- Market Basket Analysis simplifi√©\n",
        "WITH product_pairs AS (\n",
        "    SELECT\n",
        "        oi1.product_id as product_a,\n",
        "        oi2.product_id as product_b,\n",
        "        COUNT(*) as co_purchase_count\n",
        "    FROM order_items oi1\n",
        "    JOIN order_items oi2 ON oi1.order_id = oi2.order_id\n",
        "    WHERE oi1.product_id != oi2.product_id\n",
        "    GROUP BY oi1.product_id, oi2.product_id\n",
        "    HAVING COUNT(*) >= 10  -- Seuil minimum\n",
        ")\n",
        "\n",
        "SELECT\n",
        "    product_a,\n",
        "    product_b,\n",
        "    co_purchase_count,\n",
        "    co_purchase_count::float / total_a.count as confidence\n",
        "FROM product_pairs pp\n",
        "JOIN (\n",
        "    SELECT product_id, COUNT(*) as count\n",
        "    FROM order_items\n",
        "    GROUP BY product_id\n",
        ") total_a ON pp.product_a = total_a.product_id\n",
        "ORDER BY confidence DESC;\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbYkj8ItabH-"
      },
      "source": [
        "## Partie 5 : Int√©gration avec les APIs m√©t√©o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4CU6SNEfNXb"
      },
      "source": [
        "### üå§Ô∏è Croisement donn√©es m√©t√©o/ventes\n",
        "```python\n",
        "def weather_sales_correlation():\n",
        "    \"\"\"\n",
        "    Correlez vos donn√©es m√©t√©o du Notebook 1 avec les ventes\n",
        "    \n",
        "    Hypoth√®ses √† tester :\n",
        "    1. Les ventes de certaines cat√©gories augmentent-elles avec la pluie ?\n",
        "    2. Y a-t-il un impact de la temp√©rature sur les achats ?\n",
        "    3. Les livraisons sont-elles impact√©es par la m√©t√©o ?\n",
        "    \"\"\"\n",
        "    \n",
        "    # R√©cup√©rez les donn√©es m√©t√©o historiques pour les villes br√©siliennes\n",
        "    weather_query = \"\"\"\n",
        "    SELECT DISTINCT customer_city, customer_state\n",
        "    FROM customers\n",
        "    WHERE customer_state IN ('SP', 'RJ', 'MG', 'RS', 'SC')\n",
        "    ORDER BY customer_city;\n",
        "    \"\"\"\n",
        "    \n",
        "    cities = pd.read_sql(weather_query, engine)\n",
        "    \n",
        "    # Int√©grez avec l'API m√©t√©o\n",
        "    # Analysez les corr√©lations\n",
        "    \n",
        "    pass\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHG9k_5PfZXd"
      },
      "source": [
        "### üìä Dashboard g√©o-temporel\n",
        "```python\n",
        "def create_geotemporal_dashboard():\n",
        "    \"\"\"\n",
        "    Cr√©ez un dashboard interactif combinant :\n",
        "    - Carte des ventes par r√©gion\n",
        "    - √âvolution temporelle avec m√©t√©o\n",
        "    - Segments clients g√©olocalis√©s\n",
        "    - Pr√©dictions par zone g√©ographique\n",
        "    \"\"\"\n",
        "    pass\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsIuD-IVfnxW"
      },
      "source": [
        "---\n",
        "## üèÜ Livrables finaux\n",
        "\n",
        "### üìà Rapport d'analyse complet\n",
        "1. **Segmentation RFM (Recency, Frenquency, Monetary) ** : 5-7 segments avec caract√©ristiques\n",
        "2. **Analyse g√©ographique**  : Performances par r√©gion + recommandations\n",
        "3. **Pr√©dictions churn** : Liste des clients √† risque + actions\n",
        "4. **Recommandations produits** : Top 10 des associations\n",
        "5. **Impact m√©t√©o** : Corr√©lations significatives identifi√©es\n",
        "\n",
        "### üöÄ Pipeline automatis√©\n",
        "```python\n",
        "def automated_analysis_pipeline():\n",
        "    \"\"\"\n",
        "    Pipeline qui :\n",
        "    1. Se connecte √† la DB\n",
        "    2. Ex√©cute toutes les analyses\n",
        "    3. Met √† jour les segments clients\n",
        "    4. G√©n√®re le rapport automatiquement\n",
        "    5. Envoie des alertes si n√©cessaire\n",
        "    \"\"\"\n",
        "    pass\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynvmdtNftwf"
      },
      "source": [
        "## üéì Auto-√©valuation\n",
        "\n",
        "- [ ] **Connexion DB** : PostgreSQL fonctionnelle\n",
        "- [ ] **Requ√™tes complexes** : JOINs, CTEs, fonctions analytiques\n",
        "- [ ] **Gestion des erreurs** : Connexions robustes\n",
        "- [ ] **Performance** : Requ√™tes optimis√©es avec index\n",
        "- [ ] **Int√©gration** : SQL + Python + APIs\n",
        "- [ ] **Insights actionables** : Recommandations business claires\n",
        "\n",
        "### üîó Pr√©paration au Notebook 3\n",
        "Le prochain notebook portera sur NoSQL (MongoDB) avec des donn√©es de r√©seaux sociaux et d'IoT, en temps r√©el.\n",
        "\n",
        "### üí° Bases de donn√©es alternatives\n",
        "- **PlanetScale** : MySQL serverless gratuit\n",
        "- **MongoDB Atlas** : 512MB gratuit\n",
        "- **FaunaDB** : Base multi-mod√®le gratuite\n",
        "- **Hasura Cloud** : GraphQL + PostgreSQL"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
